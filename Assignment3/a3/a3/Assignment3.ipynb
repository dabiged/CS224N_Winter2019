{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Machine Learning & Neural Networks (8 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) (4 points) Adam Optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the standard Stochastic Gradient Descent update rule:\n",
    "$$\\theta \\leftarrow \\theta − \\alpha \\nabla_\\theta J_{minibatch} (\\theta)$$\n",
    "where $\\theta$ is a vector containing all of the model parameters, J is the loss function, $\\nabla \\theta J_{minibatch} (\\theta)$\n",
    "is the gradient of the loss function with respect to the parameters on a minibatch of data, and $\\alpha$ is\n",
    "the learning rate. Adam Optimization uses a more sophisticated update rule with two additional\n",
    "steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. (2 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, Adam uses a trick called momentum by keeping track of m, a rolling average\n",
    "of the gradients:\n",
    "$$m \\leftarrow \\beta_1 m + (1 − \\beta_1 ) \\nabla_\\theta J_{minibatch} (\\theta)$$\n",
    "$$\\theta ← \\theta − \\alpha m$$\n",
    "where $\\beta_1$ is a hyperparameter between 0 and 1 (often set to 0.9). \n",
    "\n",
    "Briefly explain (you don’t need\n",
    "to prove mathematically, just give an intuition) how using m stops the updates from varying\n",
    "as much and why this low variance may be helpful to learning, overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting $\\beta$ to a value near 1 weights the updates to $\\theta$ to take more of the previous values into account.\n",
    "\n",
    "$\\beta$ values near zero revert to the stochastic gradient descent update.\n",
    "\n",
    "This would be useful for escaping narrow local minima like saddle points in the loss space and look for larger, more generalisable  local minima.\n",
    "\n",
    "Adam uses a momentum term $(\\beta_1 m)$, which, with typical learning rates like 0.9, results the updated $\\textbf{m}$ to consist mostly of the previous $\\mathbf{m}_{prev}$, and allows only minor contribution from the gradient. This \"dampens\" the path of our gradient, resulting in more stable updates, and allowing us to use larger learning rates than with regular SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. (2 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam also uses adaptive learning rates by keeping track of v, a rolling average of\n",
    "the magnitudes of the gradients\n",
    "\n",
    "$$m \\leftarrow \\beta_1 m + (1 − \\beta_1 ) \\nabla_\\theta J_{minibatch} (\\theta)$$\n",
    "\n",
    "$$v \\leftarrow \\beta_2 v + (1 − \\beta_2 )(\\nabla_\\theta J_{minibatch} (\\theta) \\odot \\nabla_\\theta J_{minibatch} (\\theta))$$\n",
    "\n",
    "$$\\theta \\leftarrow \\theta − \\alpha \\odot \\frac{m}{\\sqrt{v}} $$\n",
    "\n",
    "\n",
    "where $\\odot$ and $/$ denote elementwise multiplication and division (so $z\\odot z$ is elementwise squaring)\n",
    "and $\\beta_2$ is a hyperparameter between 0 and 1 (often set to 0.99). Since Adam divides the update\n",
    "by $\\sqrt{v}$, which of the model parameters will get larger updates? Why might this help with\n",
    "learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam divides each element of the parameters $\\theta$ in the update elementwise with $\\textbf{v}$ that is produced by elementwise squaring of the gradients with respect to the parameters. The larger the gradient is for parameter $\\theta_i$, the larger the divisor for it will be, meaning that Adam evens out the scale of the updates between flatter and steeper directions. This helps the updates to make progress on plateaus while and prevents overshooting in steep directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout is a regularization technique. During training, dropout randomly sets units\n",
    "in the hidden layer h to zero with probability $p_{drop} $(dropping different units each minibatch), and\n",
    "then multiplies h by a constant $\\gamma$. We can write this as\n",
    "\n",
    "$$h_{drop} = \\gamma d \\circ h$$\n",
    "\n",
    "where $d \\in \\{0, 1\\}^{D_h}$ ($D_h$ is the size of h) is a mask vector where each entry is 0 with probability\n",
    "$p_{drop}$ and 1 with probability $(1 − p_{drop} )$. $\\gamma$ is chosen such that the expected value of $h_{drop}$ is h:\n",
    "\n",
    "$$E_{p_{drop}} [h_{drop} ]_i = h_i$$\n",
    "\n",
    "for all $i \\in {1, . . . , D_h }$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. (2 points) What must γ equal in terms of p drop ? Briefly justify your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E_{p_{drop}} [h_{drop} ]_i = h_i$$\n",
    "$$E_{p_{drop}} [\\gamma d \\circ h ]_i = h_i$$\n",
    "$$E_{p_{drop}} [ d_i \\circ h_i ] \\gamma = h_i$$\n",
    "$$ \\gamma = \\frac{h_i}{E_{p_{drop}} [ d_i  h_i ]}$$\n",
    "$$ \\gamma = \\frac{1}{E_{p_{drop}} [ d_i ]}$$\n",
    "$$ \\gamma = \\frac{1}{0 (p_{drop}) + 1(1-p_{drop}))}$$\n",
    "\n",
    "$$ \\gamma = \\frac{1}{1-p_{drop}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. (2 points) Why should we apply dropout during training but not during evaluation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training dropout acts as a method of preventing overfitting. By ensuring that the entire network is modelling sections of the input data independently we can be sure we are not training our network to fit only the input data. \n",
    "\n",
    "During evaluation the entire network should be active as we are not changing the weights/biases on the network and so we should leverage the extra power granted by the entire network without the risk of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
